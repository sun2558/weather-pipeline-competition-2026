# src/data/report_generator.py

import pandas as pd
import numpy as np
from datetime import datetime
from typing import Optional, Dict, Any
import os

class QualityReportGenerator:
    """
    ç”Ÿæˆæ°”è±¡æ•°æ®è´¨é‡æŠ¥å‘Šï¼ˆçº¯Pythonç‰ˆæœ¬ï¼‰
    """
    
    def __init__(self, raw_df: pd.DataFrame, cleaned_df: pd.DataFrame):
        """
        åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨
        
        Args:
            raw_df: åŸå§‹æ•°æ®DataFrame
            cleaned_df: æ¸…æ´—åçš„æ•°æ®DataFrame
        """
        self.raw_df = raw_df.copy()
        self.cleaned_df = cleaned_df.copy()
        self.report = {}
    
    def _get_missing_stats(self, df: pd.DataFrame, column: str = 'temperature') -> Dict[str, Any]:
        """
        è®¡ç®—ç¼ºå¤±å€¼ç»Ÿè®¡ä¿¡æ¯ï¼ˆç‹¬ç«‹å‡½æ•°ï¼Œä¸ä¾èµ–å¤–éƒ¨æ¨¡å—ï¼‰
        """
        if column not in df.columns:
            return {"error": f"åˆ— '{column}' ä¸å­˜åœ¨"}
        
        missing_mask = df[column].isna()
        total_missing = int(missing_mask.sum())
        missing_rate = total_missing / len(df) if len(df) > 0 else 0
        
        # è¿ç»­ç¼ºå¤±æ®µè½åˆ†æ
        if total_missing > 0:
            # è¯†åˆ«è¿ç»­ç¼ºå¤±æ®µè½
            groups = (missing_mask != missing_mask.shift()).cumsum()
            gap_lengths = []
            
            for group_id, group in missing_mask.groupby(groups):
                if group.any():  # è¿™æ˜¯ä¸€ä¸ªç¼ºå¤±å€¼æ®µè½
                    gap_length = int(group.sum())
                    gap_lengths.append(gap_length)
            
            stats = {
                "total_missing": total_missing,
                "missing_rate": float(missing_rate),
                "missing_percentage": f"{missing_rate * 100:.2f}%",
                "gap_count": len(gap_lengths),
                "max_gap_length": max(gap_lengths) if gap_lengths else 0,
                "avg_gap_length": np.mean(gap_lengths) if gap_lengths else 0,
                "gap_lengths": gap_lengths
            }
        else:
            stats = {
                "total_missing": 0,
                "missing_rate": 0.0,
                "missing_percentage": "0.00%",
                "gap_count": 0,
                "max_gap_length": 0,
                "avg_gap_length": 0,
                "gap_lengths": []
            }
        
        return stats
    
    def generate_basic_stats(self, column: str = 'temperature') -> Dict:
        """
        ç”ŸæˆåŸºç¡€ç»Ÿè®¡æ•°æ®
        """
        basic_stats = {}
        
        # åŸå§‹æ•°æ®ç»Ÿè®¡
        if column in self.raw_df.columns:
            raw_data = self.raw_df[column].dropna()
            basic_stats["raw_data"] = {
                "count": int(len(raw_data)),
                "mean": float(raw_data.mean()) if len(raw_data) > 0 else None,
                "std": float(raw_data.std()) if len(raw_data) > 0 else None,
                "min": float(raw_data.min()) if len(raw_data) > 0 else None,
                "max": float(raw_data.max()) if len(raw_data) > 0 else None,
                "25%": float(raw_data.quantile(0.25)) if len(raw_data) > 0 else None,
                "50%": float(raw_data.quantile(0.5)) if len(raw_data) > 0 else None,
                "75%": float(raw_data.quantile(0.75)) if len(raw_data) > 0 else None,
            }
        
        # æ¸…æ´—åæ•°æ®ç»Ÿè®¡
        if column in self.cleaned_df.columns:
            cleaned_data = self.cleaned_df[column].dropna()
            basic_stats["cleaned_data"] = {
                "count": int(len(cleaned_data)),
                "mean": float(cleaned_data.mean()) if len(cleaned_data) > 0 else None,
                "std": float(cleaned_data.std()) if len(cleaned_data) > 0 else None,
                "min": float(cleaned_data.min()) if len(cleaned_data) > 0 else None,
                "max": float(cleaned_data.max()) if len(cleaned_data) > 0 else None,
                "25%": float(cleaned_data.quantile(0.25)) if len(cleaned_data) > 0 else None,
                "50%": float(cleaned_data.quantile(0.5)) if len(cleaned_data) > 0 else None,
                "75%": float(cleaned_data.quantile(0.75)) if len(cleaned_data) > 0 else None,
            }
        
        self.report["basic_stats"] = basic_stats
        return basic_stats
    
    def generate_missing_analysis(self, column: str = 'temperature') -> Dict:
        """
        ç”Ÿæˆç¼ºå¤±å€¼åˆ†æ
        """
        raw_missing = self._get_missing_stats(self.raw_df, column)
        cleaned_missing = self._get_missing_stats(self.cleaned_df, column)
        
        missing_analysis = {
            "raw_data": raw_missing,
            "cleaned_data": cleaned_missing,
            "summary": {
                "missing_fixed": raw_missing["total_missing"] - cleaned_missing["total_missing"],
                "missing_remaining": cleaned_missing["total_missing"],
                "improvement_percentage": f"{(1 - cleaned_missing['missing_rate'] / raw_missing['missing_rate']) * 100:.2f}%" 
                                         if raw_missing['missing_rate'] > 0 else "100.00%"
            }
        }
        
        self.report["missing_analysis"] = missing_analysis
        return missing_analysis
    
    def generate_outlier_analysis(self, outlier_mask: Optional[pd.Series] = None) -> Dict:
        """
        ç”Ÿæˆå¼‚å¸¸å€¼åˆ†æ
        
        Args:
            outlier_mask: å¸ƒå°”åºåˆ—ï¼ŒTrueè¡¨ç¤ºå¼‚å¸¸å€¼
        """
        if outlier_mask is not None:
            outlier_count = int(outlier_mask.sum())
            outlier_rate = outlier_count / len(self.raw_df) if len(self.raw_df) > 0 else 0
            
            outlier_analysis = {
                "detected_outliers": {
                    "count": outlier_count,
                    "rate": float(outlier_rate),
                    "percentage": f"{outlier_rate * 100:.2f}%"
                },
                "method": "3ÏƒåŸåˆ™æ£€æµ‹"
            }
        else:
            # å¦‚æœæ²¡æœ‰æä¾›å¼‚å¸¸å€¼æ©ç ï¼Œå°è¯•è‡ªåŠ¨æ£€æµ‹
            outlier_analysis = self._auto_detect_outliers()
        
        self.report["outlier_analysis"] = outlier_analysis
        return outlier_analysis
    
    def _auto_detect_outliers(self) -> Dict:
        """
        è‡ªåŠ¨æ£€æµ‹å¼‚å¸¸å€¼ï¼ˆåŸºäº3ÏƒåŸåˆ™ï¼‰
        """
        outlier_analysis = {"method": "è‡ªåŠ¨æ£€æµ‹ (3ÏƒåŸåˆ™)"}
        
        for col in ['temperature']:  # å¯ä»¥æ‰©å±•åˆ°æ›´å¤šåˆ—
            if col in self.raw_df.columns:
                data = self.raw_df[col].dropna()
                if len(data) > 0:
                    mean_val = data.mean()
                    std_val = data.std()
                    upper_bound = mean_val + 3 * std_val
                    lower_bound = mean_val - 3 * std_val
                    
                    outliers = ((self.raw_df[col] > upper_bound) | 
                               (self.raw_df[col] < lower_bound)).sum()
                    
                    outlier_analysis[col] = {
                        "mean": float(mean_val),
                        "std": float(std_val),
                        "upper_3sigma": float(upper_bound),
                        "lower_3sigma": float(lower_bound),
                        "outlier_count": int(outliers),
                        "outlier_percentage": f"{(outliers / len(self.raw_df)) * 100:.2f}%" 
                                             if len(self.raw_df) > 0 else "0.00%"
                    }
        
        return outlier_analysis
    
    def generate_data_quality_summary(self) -> Dict:
        """
        ç”Ÿæˆæ•°æ®è´¨é‡æ‘˜è¦
        """
        summary = {
            "report_generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "data_overview": {
                "raw_data_shape": self.raw_df.shape,
                "cleaned_data_shape": self.cleaned_df.shape,
                "columns": list(self.raw_df.columns) if hasattr(self.raw_df, 'columns') else [],
            },
            "quality_indicators": {}
        }
        
        # è®¡ç®—è´¨é‡æŒ‡æ ‡
        if "missing_analysis" in self.report:
            missing_info = self.report["missing_analysis"]
            summary["quality_indicators"]["completeness"] = {
                "raw": 1 - missing_info["raw_data"]["missing_rate"],
                "cleaned": 1 - missing_info["cleaned_data"]["missing_rate"],
                "improvement": missing_info["summary"]["improvement_percentage"]
            }
        
        self.report["summary"] = summary
        return summary
    
    def generate_full_report(self, 
                            column: str = 'temperature',
                            outlier_mask: Optional[pd.Series] = None) -> Dict:
        """
        ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
        
        Returns:
            åŒ…å«æ‰€æœ‰åˆ†æçš„æŠ¥å‘Šå­—å…¸
        """
        print("\n" + "="*60)
        print("ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š")
        print("="*60)
        
        # ç”Ÿæˆå„ä¸ªéƒ¨åˆ†
        self.generate_basic_stats(column)
        print("âœ“ åŸºç¡€ç»Ÿè®¡å®Œæˆ")
        
        self.generate_missing_analysis(column)
        print("âœ“ ç¼ºå¤±å€¼åˆ†æå®Œæˆ")
        
        self.generate_outlier_analysis(outlier_mask)
        print("âœ“ å¼‚å¸¸å€¼åˆ†æå®Œæˆ")
        
        self.generate_data_quality_summary()
        print("âœ“ è´¨é‡æ‘˜è¦å®Œæˆ")
        
        # æ·»åŠ æ•°æ®ç¤ºä¾‹
        self.report["data_samples"] = {
            "raw_first_5": self.raw_df.head().to_dict(orient='records'),
            "cleaned_first_5": self.cleaned_df.head().to_dict(orient='records')
        }
        
        print("\nâœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ!")
        print(f"æŠ¥å‘ŠåŒ…å« {len(self.report)} ä¸ªéƒ¨åˆ†")
        
        # åœ¨æ§åˆ¶å°æ˜¾ç¤ºç®€è¦æŠ¥å‘Š
        self._print_console_summary()
        
        return self.report
    
    def _print_console_summary(self):
        """åœ¨æ§åˆ¶å°æ‰“å°ç®€è¦æŠ¥å‘Š"""
        print("\nğŸ“Š æ•°æ®è´¨é‡ç®€è¦æŠ¥å‘Š:")
        print("-" * 40)
        
        # æ•°æ®æ¦‚å†µ
        if "summary" in self.report:
            summary = self.report["summary"]
            print(f"ğŸ“ˆ æ•°æ®æ¦‚å†µ:")
            print(f"  åŸå§‹æ•°æ®: {summary['data_overview']['raw_data_shape'][0]} è¡Œ, "
                  f"{summary['data_overview']['raw_data_shape'][1]} åˆ—")
            print(f"  æ¸…æ´—åæ•°æ®: {summary['data_overview']['cleaned_data_shape'][0]} è¡Œ, "
                  f"{summary['data_overview']['cleaned_data_shape'][1]} åˆ—")
        
        # ç¼ºå¤±å€¼æƒ…å†µ
        if "missing_analysis" in self.report:
            missing = self.report["missing_analysis"]
            print(f"\nâš ï¸  ç¼ºå¤±å€¼æƒ…å†µ:")
            print(f"  åŸå§‹æ•°æ®ç¼ºå¤±ç‡: {missing['raw_data']['missing_percentage']}")
            print(f"  æ¸…æ´—åç¼ºå¤±ç‡: {missing['cleaned_data']['missing_percentage']}")
            print(f"  ä¿®å¤ç‡: {missing['summary']['improvement_percentage']}")
        
        # å¼‚å¸¸å€¼æƒ…å†µ
        if "outlier_analysis" in self.report:
            outlier = self.report["outlier_analysis"]
            if "detected_outliers" in outlier:
                print(f"\nğŸš¨ å¼‚å¸¸å€¼æƒ…å†µ:")
                print(f"  æ£€æµ‹åˆ°å¼‚å¸¸å€¼: {outlier['detected_outliers']['count']} ä¸ª")
                print(f"  å¼‚å¸¸å€¼æ¯”ä¾‹: {outlier['detected_outliers']['percentage']}")
        
        # ç”Ÿæˆæ—¶é—´
        if "summary" in self.report:
            print(f"\nğŸ• æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {self.report['summary']['report_generated_at']}")
        
        print("="*60)
    
    def save_report(self, 
                   format: str = "txt", 
                   path: str = "./reports/quality_report.txt"):
        """
        ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        
        Args:
            format: æ–‡ä»¶æ ¼å¼ (txt, json, markdown)
            path: æ–‡ä»¶ä¿å­˜è·¯å¾„
        """
        os.makedirs(os.path.dirname(path), exist_ok=True)
        
        if format == "txt":
            self._save_as_txt(path)
        elif format == "json":
            self._save_as_json(path)
        elif format == "markdown":
            self._save_as_markdown(path)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼: {format}ï¼Œè¯·ä½¿ç”¨ txt, json æˆ– markdown")
        
        print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {path}")
    
    def _save_as_txt(self, path: str):
        """ä¿å­˜ä¸ºæ–‡æœ¬æ–‡ä»¶"""
        with open(path, 'w', encoding='utf-8') as f:
            f.write("="*60 + "\n")
            f.write("æ°”è±¡æ•°æ®è´¨é‡æŠ¥å‘Š\n")
            f.write("="*60 + "\n\n")
            
            # æ•°æ®æ¦‚å†µ
            if "summary" in self.report:
                summary = self.report["summary"]
                f.write("1. æ•°æ®æ¦‚å†µ\n")
                f.write("-"*40 + "\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {summary['report_generated_at']}\n")
                f.write(f"åŸå§‹æ•°æ®å½¢çŠ¶: {summary['data_overview']['raw_data_shape']}\n")
                f.write(f"æ¸…æ´—åæ•°æ®å½¢çŠ¶: {summary['data_overview']['cleaned_data_shape']}\n")
                f.write(f"æ•°æ®åˆ—: {', '.join(summary['data_overview']['columns'])}\n\n")
            
            # åŸºç¡€ç»Ÿè®¡
            if "basic_stats" in self.report:
                f.write("2. åŸºç¡€ç»Ÿè®¡åˆ†æ\n")
                f.write("-"*40 + "\n")
                
                for data_type, stats in self.report["basic_stats"].items():
                    f.write(f"\n{data_type}:\n")
                    for key, value in stats.items():
                        if value is not None:
                            f.write(f"  {key}: {value}\n")
                f.write("\n")
            
            # ç¼ºå¤±å€¼åˆ†æ
            if "missing_analysis" in self.report:
                f.write("3. ç¼ºå¤±å€¼åˆ†æ\n")
                f.write("-"*40 + "\n")
                
                missing = self.report["missing_analysis"]
                f.write(f"\nåŸå§‹æ•°æ®:\n")
                for key, value in missing["raw_data"].items():
                    if key != "gap_lengths":
                        f.write(f"  {key}: {value}\n")
                
                f.write(f"\næ¸…æ´—åæ•°æ®:\n")
                for key, value in missing["cleaned_data"].items():
                    if key != "gap_lengths":
                        f.write(f"  {key}: {value}\n")
                
                f.write(f"\nå¤„ç†æ‘˜è¦:\n")
                for key, value in missing["summary"].items():
                    f.write(f"  {key}: {value}\n")
                f.write("\n")
            
            # å¼‚å¸¸å€¼åˆ†æ
            if "outlier_analysis" in self.report:
                f.write("4. å¼‚å¸¸å€¼åˆ†æ\n")
                f.write("-"*40 + "\n")
                
                outlier = self.report["outlier_analysis"]
                if "detected_outliers" in outlier:
                    for key, value in outlier["detected_outliers"].items():
                        f.write(f"  {key}: {value}\n")
                f.write(f"æ£€æµ‹æ–¹æ³•: {outlier.get('method', 'N/A')}\n\n")
            
            f.write("="*60 + "\n")
            f.write("æŠ¥å‘Šç»“æŸ\n")
            f.write("="*60 + "\n")
    
    def _save_as_json(self, path: str):
        """ä¿å­˜ä¸ºJSONæ–‡ä»¶"""
        import json
        
        # è½¬æ¢ä¸èƒ½åºåˆ—åŒ–çš„å¯¹è±¡
        def default_serializer(obj):
            if isinstance(obj, (np.integer, np.floating)):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, pd.Timestamp):
                return obj.isoformat()
            return str(obj)
        
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(self.report, f, indent=2, default=default_serializer, ensure_ascii=False)
    
    def _save_as_markdown(self, path: str):
        """ä¿å­˜ä¸ºMarkdownæ–‡ä»¶"""
        with open(path, 'w', encoding='utf-8') as f:
            f.write("# æ°”è±¡æ•°æ®è´¨é‡æŠ¥å‘Š\n\n")
            
            # æ•°æ®æ¦‚å†µ
            if "summary" in self.report:
                summary = self.report["summary"]
                f.write(f"**ç”Ÿæˆæ—¶é—´**: {summary['report_generated_at']}\n\n")
                
                f.write("## 1. æ•°æ®æ¦‚å†µ\n\n")
                f.write(f"- **åŸå§‹æ•°æ®**: {summary['data_overview']['raw_data_shape'][0]} è¡Œ Ã— {summary['data_overview']['raw_data_shape'][1]} åˆ—\n")
                f.write(f"- **æ¸…æ´—åæ•°æ®**: {summary['data_overview']['cleaned_data_shape'][0]} è¡Œ Ã— {summary['data_overview']['cleaned_data_shape'][1]} åˆ—\n")
                f.write(f"- **æ•°æ®åˆ—**: {', '.join(summary['data_overview']['columns'])}\n\n")
            
            # åŸºç¡€ç»Ÿè®¡
            if "basic_stats" in self.report:
                f.write("## 2. åŸºç¡€ç»Ÿè®¡åˆ†æ\n\n")
                
                for data_type, stats in self.report["basic_stats"].items():
                    f.write(f"### {data_type.replace('_', ' ').title()}\n\n")
                    f.write("| æŒ‡æ ‡ | å€¼ |\n")
                    f.write("|------|----|\n")
                    for key, value in stats.items():
                        if value is not None:
                            f.write(f"| {key} | {value} |\n")
                    f.write("\n")
            
            # ç¼ºå¤±å€¼åˆ†æ
            if "missing_analysis" in self.report:
                f.write("## 3. ç¼ºå¤±å€¼åˆ†æ\n\n")
                
                missing = self.report["missing_analysis"]
                f.write("### åŸå§‹æ•°æ®\n\n")
                f.write("| æŒ‡æ ‡ | å€¼ |\n")
                f.write("|------|----|\n")
                for key, value in missing["raw_data"].items():
                    if key != "gap_lengths":
                        f.write(f"| {key} | {value} |\n")
                
                f.write("\n### æ¸…æ´—åæ•°æ®\n\n")
                f.write("| æŒ‡æ ‡ | å€¼ |\n")
                f.write("|------|----|\n")
                for key, value in missing["cleaned_data"].items():
                    if key != "gap_lengths":
                        f.write(f"| {key} | {value} |\n")
                
                f.write("\n### å¤„ç†æ‘˜è¦\n\n")
                f.write("| æŒ‡æ ‡ | å€¼ |\n")
                f.write("|------|----|\n")
                for key, value in missing["summary"].items():
                    f.write(f"| {key} | {value} |\n")
                f.write("\n")
            
            # å¼‚å¸¸å€¼åˆ†æ
            if "outlier_analysis" in self.report:
                f.write("## 4. å¼‚å¸¸å€¼åˆ†æ\n\n")
                
                outlier = self.report["outlier_analysis"]
                f.write(f"**æ£€æµ‹æ–¹æ³•**: {outlier.get('method', 'N/A')}\n\n")
                
                if "detected_outliers" in outlier:
                    f.write("| æŒ‡æ ‡ | å€¼ |\n")
                    f.write("|------|----|\n")
                    for key, value in outlier["detected_outliers"].items():
                        f.write(f"| {key} | {value} |\n")
                    f.write("\n")
            
            f.write("---\n")
            f.write("*æŠ¥å‘Šç»“æŸ*\n")


# ä¾¿æ·å‡½æ•°
def generate_quality_report(raw_df: pd.DataFrame, 
                           cleaned_df: pd.DataFrame,
                           column: str = 'temperature',
                           outlier_mask: Optional[pd.Series] = None,
                           save_format: str = 'txt',
                           save_path: str = './reports/quality_report.txt') -> QualityReportGenerator:
    """
    å¿«é€Ÿç”Ÿæˆå¹¶ä¿å­˜è´¨é‡æŠ¥å‘Šçš„ä¾¿æ·å‡½æ•°
    
    Returns:
        æŠ¥å‘Šç”Ÿæˆå™¨å®ä¾‹
    """
    # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
    report_gen = QualityReportGenerator(raw_df, cleaned_df)
    
    # ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
    report_gen.generate_full_report(column=column, outlier_mask=outlier_mask)
    
    # ä¿å­˜æŠ¥å‘Š
    report_gen.save_report(format=save_format, path=save_path)
    
    return report_gen


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨æ¨¡å—...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    dates = pd.date_range("2024-01-01", periods=100, freq="H")
    temperatures = np.random.normal(20, 5, 100)
    
    # æ·»åŠ ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼
    temperatures[10:15] = np.nan  # è¿ç»­ç¼ºå¤±
    temperatures[50] = 100  # å¼‚å¸¸å€¼
    
    raw_df = pd.DataFrame({
        "timestamp": dates,
        "temperature": temperatures
    })
    
    # æ¨¡æ‹Ÿæ¸…æ´—è¿‡ç¨‹
    cleaned_df = raw_df.copy()
    cleaned_df["temperature"] = cleaned_df["temperature"].interpolate()
    
    # åˆ›å»ºå¼‚å¸¸å€¼æ©ç ï¼ˆæ¨¡æ‹Ÿæ£€æµ‹ç»“æœï¼‰
    outlier_mask = pd.Series([False] * 100)
    outlier_mask[50] = True
    
    # æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ
    print("\nç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")
    report_gen = generate_quality_report(
        raw_df=raw_df,
        cleaned_df=cleaned_df,
        column="temperature",
        outlier_mask=outlier_mask,
        save_format="txt",
        save_path="./reports/test_report.txt"
    )
    
    print("\nâœ… æµ‹è¯•å®Œæˆ!")
# run_pipeline.py - æ ¡èµ›æœ€ç»ˆä¼˜åŒ–ç‰ˆ
import os
import sys
import pandas as pd
import importlib.util
from datetime import datetime

print("=" * 60)
print("æ°”è±¡æ•°æ®å¤„ç†ç®¡é“ - æ ¡èµ›æ¼”ç¤ºç‰ˆ")
print("=" * 60)

# é¡¹ç›®æ ¹ç›®å½•
current_dir = os.path.dirname(os.path.abspath(__file__))
print(f"é¡¹ç›®æ ¹ç›®å½•: {current_dir}")

# src/date ç›®å½•
src_date_dir = os.path.join(current_dir, "src", "date")
print(f"æ¨¡å—ç›®å½•: {src_date_dir}")

if not os.path.exists(src_date_dir):
    print("âŒ é”™è¯¯: æ‰¾ä¸åˆ° src/date/ ç›®å½•")
    sys.exit(1)

# æ£€æŸ¥æ–‡ä»¶
print("\nğŸ“ æ£€æŸ¥æ¨¡å—æ–‡ä»¶...")
module_files = {
    "loader": "loader.py",
    "imputation": "imputation.py", 
    "quality_check": "quality_check.py",
    "report_generator": "report_generator.py"
}

modules = {}
for name, filename in module_files.items():
    path = os.path.join(src_date_dir, filename)
    if os.path.exists(path):
        print(f"  âœ… {filename}: å­˜åœ¨")
        modules[name] = path
    else:
        print(f"  âŒ {filename}: ä¸å­˜åœ¨")
        # å¦‚æœå…³é”®æ¨¡å—ç¼ºå¤±ï¼Œå°è¯•åˆ›å»ºç®€å•ç‰ˆæœ¬
        if filename in ["quality_check.py", "report_generator.py"]:
            print(f"    è­¦å‘Š: {filename} ç¼ºå¤±ï¼Œä½†æœ¬ç‰ˆæœ¬å·²å†…ç½®ç›¸å…³åŠŸèƒ½")

print("\n" + "=" * 60)
print("å¼€å§‹å¯¼å…¥æ¨¡å—...")
print("=" * 60)

# å¯¼å…¥æ¨¡å—å‡½æ•°
def import_module(name, path):
    spec = importlib.util.spec_from_file_location(name, path)
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)
    return module

try:
    # å¯¼å…¥å¯ç”¨çš„æ¨¡å—
    if "loader" in modules:
        loader = import_module("loader", modules["loader"])
        load_weather_data = loader.load_weather_data
    else:
        # å¤‡ç”¨åŠ è½½å‡½æ•°
        def load_weather_data(filepath):
            print(f"  ä½¿ç”¨å¤‡ç”¨åŠ è½½å™¨: {filepath}")
            return pd.read_csv(filepath)
    
    if "imputation" in modules:
        imputation = import_module("imputation", modules["imputation"])
        linear_impute = imputation.linear_impute
    else:
        # å¤‡ç”¨æ’å€¼å‡½æ•°
        def linear_impute(data, column='temperature', max_gap=5, method='linear'):
            print(f"  ä½¿ç”¨å¤‡ç”¨æ’å€¼: {column}")
            return data.copy()
    
    # å†…ç½®æ ‡å‡†åŒ–å‡½æ•°
    def zscore_normalize(data, columns=None):
        """Z-scoreæ ‡å‡†åŒ–ï¼ˆå†…ç½®ç‰ˆæœ¬ï¼‰"""
        if columns is None:
            columns = data.select_dtypes(include=['number']).columns
        
        result = data.copy()
        for col in columns:
            if col in data.columns and data[col].notna().any():
                mean_val = data[col].mean()
                std_val = data[col].std()
                if std_val > 0:
                    result[col] = (data[col] - mean_val) / std_val
                else:
                    result[col] = 0
        return result
    
    # å†…ç½®å¼‚å¸¸æ£€æµ‹
    def three_sigma_detect(data, columns=None, sigma=3):
        """3ÏƒåŸåˆ™å¼‚å¸¸æ£€æµ‹"""
        if columns is None:
            columns = data.select_dtypes(include=['number']).columns
        
        outlier_info = {}
        for col in columns:
            if col in data.columns and data[col].notna().any():
                col_data = data[col].dropna()
                if len(col_data) > 0:
                    mean_val = col_data.mean()
                    std_val = col_data.std()
                    if std_val > 0:
                        upper = mean_val + sigma * std_val
                        lower = mean_val - sigma * std_val
                        mask = (data[col] > upper) | (data[col] < lower)
                        outlier_info[col] = {
                            'mask': mask,
                            'count': mask.sum(),
                            'mean': mean_val,
                            'std': std_val,
                            'upper': upper,
                            'lower': lower
                        }
        return outlier_info
    
    # å†…ç½®æŠ¥å‘Šç”Ÿæˆ
    def generate_quality_report(raw_df, cleaned_df, column=None, 
                               outlier_info=None, save_path="quality_report.txt"):
        """ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Šï¼ˆå†…ç½®ç‰ˆæœ¬ï¼‰"""
        if column is None:
            numeric_cols = raw_df.select_dtypes(include=['number']).columns
            column = numeric_cols[0] if len(numeric_cols) > 0 else raw_df.columns[0]
        
        report_lines = []
        report_lines.append("=" * 60)
        report_lines.append("æ°”è±¡æ•°æ®è´¨é‡åˆ†ææŠ¥å‘Š - æ ¡èµ›æ¼”ç¤ºç‰ˆ")
        report_lines.append("=" * 60)
        
        # 1. æ•°æ®æ¦‚å†µ
        report_lines.append("\n1. æ•°æ®æ¦‚å†µ")
        report_lines.append("-" * 40)
        report_lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append(f"åŸå§‹æ•°æ®å½¢çŠ¶: {raw_df.shape}")
        report_lines.append(f"æ¸…æ´—åæ•°æ®å½¢çŠ¶: {cleaned_df.shape}")
        report_lines.append(f"æ•°æ®åˆ—: {', '.join(raw_df.columns.tolist())}")
        report_lines.append(f"ä¸»åˆ†æåˆ—: {column}")
        
        # 2. åŸºç¡€ç»Ÿè®¡
        report_lines.append("\n2. åŸºç¡€ç»Ÿè®¡åˆ†æ")
        report_lines.append("-" * 40)
        
        if column in raw_df.columns:
            raw_col = raw_df[column].dropna()
            if len(raw_col) > 0:
                report_lines.append(f"\n[{column}] - åŸå§‹æ•°æ®:")
                report_lines.append(f"  æ•°é‡: {len(raw_col):,}")
                report_lines.append(f"  å‡å€¼: {raw_col.mean():.4f}")
                report_lines.append(f"  æ ‡å‡†å·®: {raw_col.std():.4f}")
                report_lines.append(f"  æœ€å°å€¼: {raw_col.min():.4f}")
                report_lines.append(f"  æœ€å¤§å€¼: {raw_col.max():.4f}")
        
        if column in cleaned_df.columns:
            cleaned_col = cleaned_df[column].dropna()
            if len(cleaned_col) > 0:
                report_lines.append(f"\n[{column}] - æ¸…æ´—åæ•°æ®:")
                report_lines.append(f"  æ•°é‡: {len(cleaned_col):,}")
                report_lines.append(f"  å‡å€¼: {cleaned_col.mean():.4f}")
                report_lines.append(f"  æ ‡å‡†å·®: {cleaned_col.std():.4f}")
                report_lines.append(f"  æœ€å°å€¼: {cleaned_col.min():.4f}")
                report_lines.append(f"  æœ€å¤§å€¼: {cleaned_col.max():.4f}")
        
        # 3. ç¼ºå¤±å€¼åˆ†æ
        report_lines.append("\n3. ç¼ºå¤±å€¼åˆ†æ")
        report_lines.append("-" * 40)
        
        numeric_cols = raw_df.select_dtypes(include=['number']).columns
        for col in numeric_cols:
            if col in raw_df.columns:
                missing_before = raw_df[col].isna().sum()
                missing_after = cleaned_df[col].isna().sum() if col in cleaned_df.columns else missing_before
                if missing_before > 0:
                    report_lines.append(f"\n[{col}]:")
                    report_lines.append(f"  åŸå§‹ç¼ºå¤±: {missing_before:,} ä¸ª ({missing_before/len(raw_df)*100:.1f}%)")
                    report_lines.append(f"  æ¸…æ´—åç¼ºå¤±: {missing_after:,} ä¸ª")
                    report_lines.append(f"  ä¿®å¤æ•°é‡: {missing_before - missing_after:,} ä¸ª")
        
        # 4. å¼‚å¸¸å€¼åˆ†æ
        report_lines.append("\n4. å¼‚å¸¸å€¼åˆ†æ")
        report_lines.append("-" * 40)
        
        if outlier_info:
            total_outliers = sum(info.get('count', 0) for info in outlier_info.values())
            report_lines.append(f"æ£€æµ‹æ–¹æ³•: 3ÏƒåŸåˆ™")
            report_lines.append(f"æ€»å¼‚å¸¸å€¼æ•°é‡: {total_outliers:,}")
            
            for col, info in outlier_info.items():
                if info.get('count', 0) > 0:
                    report_lines.append(f"\n[{col}]:")
                    report_lines.append(f"  å¼‚å¸¸å€¼: {info['count']:,} ä¸ª")
                    report_lines.append(f"  æ£€æµ‹é˜ˆå€¼: [{info.get('lower', 0):.2f}, {info.get('upper', 0):.2f}]")
        
        # 5. å¤„ç†æ‘˜è¦
        report_lines.append("\n5. å¤„ç†æ‘˜è¦")
        report_lines.append("-" * 40)
        
        total_missing_before = raw_df[numeric_cols].isna().sum().sum()
        total_missing_after = cleaned_df[numeric_cols].isna().sum().sum()
        
        report_lines.append(f"å¤„ç†æ•°æ®æ€»é‡: {len(raw_df):,} è¡Œ Ã— {len(numeric_cols)} åˆ—")
        report_lines.append(f"ä¿®å¤ç¼ºå¤±å€¼: {total_missing_before - total_missing_after:,} ä¸ª")
        report_lines.append(f"æ•°æ®è´¨é‡æå‡: {(total_missing_before - total_missing_after)/max(total_missing_before, 1)*100:.1f}%")
        
        report_lines.append("\n" + "=" * 60)
        report_lines.append("æŠ¥å‘Šç»“æŸ")
        report_lines.append("=" * 60)
        
        # ä¿å­˜æŠ¥å‘Š
        report_content = "\n".join(report_lines)
        with open(save_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        return report_content
    
    print("âœ… æ‰€æœ‰æ¨¡å—åŠ è½½æˆåŠŸï¼ˆå«å†…ç½®åŠŸèƒ½ï¼‰")
    
except Exception as e:
    print(f"âŒ æ¨¡å—åŠ è½½å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# ==================== æ•°æ®åŠ è½½ç­–ç•¥ ====================
print("\n" + "=" * 60)
print("æ•°æ®åŠ è½½ç­–ç•¥")
print("=" * 60)

# 1. ä¼˜å…ˆä½¿ç”¨æ¼”ç¤ºæ•°æ®
demo_data_path = os.path.join(current_dir, "demo_data.csv")
# 2. å¤‡ç”¨ï¼šåŸå§‹æµ‹è¯•æ•°æ®
weather_data_path = os.path.join(current_dir, "data", "raw", "weather.csv")

data_path = None
data_source = ""

if os.path.exists(demo_data_path):
    data_path = demo_data_path
    data_source = "æ¼”ç¤ºæ•°æ® (demo_data.csv)"
    print(f"ğŸ“Š ä½¿ç”¨: {data_source}")
    print(f"   ä½ç½®: {data_path}")
elif os.path.exists(weather_data_path):
    data_path = weather_data_path
    data_source = "ç¤ºä¾‹æ•°æ® (weather.csv)"
    print(f"ğŸ“Š ä½¿ç”¨: {data_source}")
    print(f"   ä½ç½®: {data_path}")
    print("âš ï¸  æç¤º: å»ºè®®è¿è¡Œ create_demo_data.py ç”Ÿæˆæ›´ä¸°å¯Œçš„æ¼”ç¤ºæ•°æ®")
else:
    print("âŒ é”™è¯¯: æ‰¾ä¸åˆ°ä»»ä½•æ•°æ®æ–‡ä»¶")
    print(f"   æ£€æŸ¥: {demo_data_path}")
    print(f"   æˆ–: {weather_data_path}")
    sys.exit(1)

print("\n" + "=" * 60)
print("å¼€å§‹å¤„ç†æ•°æ®...")
print("=" * 60)

# 1. åŠ è½½æ•°æ®
print(f"\n[1/5] åŠ è½½æ•°æ® ({data_source})...")
try:
    raw_df = pd.read_csv(data_path) if 'loader' not in modules else load_weather_data(data_path)
    print(f"   âœ… åŠ è½½æˆåŠŸ: {raw_df.shape[0]:,} è¡Œ Ã— {raw_df.shape[1]} åˆ—")
    
    # ç¡®å®šæ•°å€¼åˆ—
    numeric_cols = raw_df.select_dtypes(include=['number']).columns.tolist()
    if len(numeric_cols) == 0:
        print("   âš ï¸  è­¦å‘Š: æ•°æ®ä¸­æ²¡æœ‰æ•°å€¼åˆ—ï¼Œä½¿ç”¨æ‰€æœ‰åˆ—")
        numeric_cols = raw_df.columns.tolist()
    
    # ä¸»åˆ†æåˆ—ï¼ˆç”¨äºè¯¦ç»†æŠ¥å‘Šï¼‰
    target_col = numeric_cols[0] if len(numeric_cols) > 0 else raw_df.columns[0]
    
    print(f"   å¤„ç†åˆ—: {', '.join(numeric_cols[:3])}{'...' if len(numeric_cols) > 3 else ''}")
    print(f"   ä¸»åˆ†æåˆ—: {target_col}")
    
except Exception as e:
    print(f"   âŒ åŠ è½½å¤±è´¥: {e}")
    sys.exit(1)

# 2. å¼‚å¸¸æ£€æµ‹ï¼ˆå¤šåˆ—ï¼‰
print(f"\n[2/5] å¼‚å¸¸æ£€æµ‹ (3ÏƒåŸåˆ™)...")
try:
    outlier_info = three_sigma_detect(raw_df, columns=numeric_cols, sigma=3)
    total_outliers = sum(info.get('count', 0) for info in outlier_info.values())
    
    print(f"   âœ… æ£€æµ‹å®Œæˆ:")
    print(f"      æ€»å¼‚å¸¸å€¼: {total_outliers:,} ä¸ª")
    
    # æ˜¾ç¤ºå¼‚å¸¸å€¼è¾ƒå¤šçš„åˆ—
    for col, info in outlier_info.items():
        if info.get('count', 0) > 0:
            print(f"      {col}: {info['count']:,} ä¸ªå¼‚å¸¸å€¼")
    
    # ä¸»åˆ†æåˆ—çš„æ©ç 
    target_outlier_mask = outlier_info.get(target_col, {}).get('mask', None)
    
except Exception as e:
    print(f"   âŒ å¼‚å¸¸æ£€æµ‹å¤±è´¥: {e}")
    outlier_info = {}
    target_outlier_mask = None

# 3. æ•°æ®å¤„ç†æµç¨‹
cleaned_df = raw_df.copy()

# 4. ç¼ºå¤±å€¼æ’å€¼ï¼ˆé€åˆ—å¤„ç†ï¼‰
print(f"\n[3/5] ç¼ºå¤±å€¼æ’å€¼...")
try:
    missing_before_total = cleaned_df[numeric_cols].isna().sum().sum()
    
    for col in numeric_cols:
        if col in cleaned_df.columns:
            missing_before = cleaned_df[col].isna().sum()
            if missing_before > 0:
                # ä½¿ç”¨çº¿æ€§æ’å€¼
                if 'imputation' in modules:
                    cleaned_df = linear_impute(cleaned_df, column=col, max_gap=5, method='linear')
                else:
                    # ç®€å•å‰å‘å¡«å……
                    cleaned_df[col] = cleaned_df[col].fillna(method='ffill').fillna(method='bfill')
    
    missing_after_total = cleaned_df[numeric_cols].isna().sum().sum()
    fixed_count = missing_before_total - missing_after_total
    
    print(f"   âœ… æ’å€¼å®Œæˆ:")
    print(f"      ä¿®å¤ç¼ºå¤±å€¼: {fixed_count:,} ä¸ª")
    print(f"      å‰©ä½™ç¼ºå¤±å€¼: {missing_after_total:,} ä¸ª")
    
except Exception as e:
    print(f"   âŒ æ’å€¼å¤±è´¥: {e}")

# 5. æ•°æ®æ ‡å‡†åŒ–
print(f"\n[4/5] æ•°æ®æ ‡å‡†åŒ– (Z-score)...")
try:
    cleaned_df = zscore_normalize(cleaned_df, columns=numeric_cols)
    print(f"   âœ… æ ‡å‡†åŒ–å®Œæˆ")
    print(f"      æ ‡å‡†åŒ–åˆ—: {len(numeric_cols)} ä¸ªæ•°å€¼åˆ—")
except Exception as e:
    print(f"   âŒ æ ‡å‡†åŒ–å¤±è´¥: {e}")

# 6. ç”ŸæˆæŠ¥å‘Š
print(f"\n[5/5] ç”Ÿæˆè´¨é‡æŠ¥å‘Š...")
try:
    reports_dir = os.path.join(current_dir, "reports")
    os.makedirs(reports_dir, exist_ok=True)
    report_path = os.path.join(reports_dir, "quality_report.txt")
    
    if 'report_generator' in modules and modules.get('report_generator'):
        # ä½¿ç”¨å¤–éƒ¨æ¨¡å—
        report_gen = import_module("report_generator", modules["report_generator"])
        report = report_gen.generate_quality_report(
            raw_df=raw_df,
            cleaned_df=cleaned_df,
            column=target_col,
            outlier_mask=target_outlier_mask,
            save_format="txt",
            save_path=report_path
        )
    else:
        # ä½¿ç”¨å†…ç½®å‡½æ•°
        report = generate_quality_report(
            raw_df=raw_df,
            cleaned_df=cleaned_df,
            column=target_col,
            outlier_info=outlier_info,
            save_path=report_path
        )
    
    print(f"   âœ… æŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
    print(f"      æŠ¥å‘Šä½ç½®: {report_path}")
    
    # æ˜¾ç¤ºæŠ¥å‘Šæ‘˜è¦
    if os.path.exists(report_path):
        print(f"\nğŸ“„ æŠ¥å‘Šæ‘˜è¦:")
        with open(report_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            # æ˜¾ç¤ºå…³é”®ä¿¡æ¯
            for i, line in enumerate(lines):
                if i < 15 or "ç¼ºå¤±å€¼åˆ†æ" in line or "å¼‚å¸¸å€¼åˆ†æ" in line or "å¤„ç†æ‘˜è¦" in line:
                    if line.strip():
                        print(f"      {line.rstrip()}")
                if i > 30:  # åªæ˜¾ç¤ºå‰é¢éƒ¨åˆ†
                    break
    
except Exception as e:
    print(f"   âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

print("\n" + "=" * 60)
print("ğŸ‰ æ•°æ®å¤„ç†ç®¡é“æ‰§è¡Œå®Œæˆï¼")
print("=" * 60)
print(f"ğŸ“ˆ å¤„ç†ç»Ÿè®¡:")
print(f"   æ•°æ®æº: {data_source}")
print(f"   åŸå§‹æ•°æ®: {raw_df.shape[0]:,} è¡Œ Ã— {raw_df.shape[1]} åˆ—")
print(f"   æ¸…æ´—åæ•°æ®: {cleaned_df.shape[0]:,} è¡Œ Ã— {cleaned_df.shape[1]} åˆ—")
print(f"   ä¿®å¤ç¼ºå¤±å€¼: {missing_before_total - missing_after_total:,} ä¸ª")
print(f"   æ£€æµ‹å¼‚å¸¸å€¼: {total_outliers:,} ä¸ª")
print(f"   å¤„ç†æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")

if 'report_path' in locals() and os.path.exists(report_path):
    print(f"\nğŸ“ å®Œæ•´æŠ¥å‘Š: {report_path}")
    print(f"ğŸ’¡ æç¤º: ä½¿ç”¨ 'cat {report_path}' æˆ–æ–‡æœ¬ç¼–è¾‘å™¨æŸ¥çœ‹å®Œæ•´æŠ¥å‘Š")

print("=" * 60)